{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2650f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import date, timedelta\n",
    "from sqlalchemy.orm import declarative_base, relationship, sessionmaker\n",
    "from sqlalchemy import create_engine, Column, Integer, String, ForeignKey, Date, Float\n",
    "import sqlite3\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_sql_code_block(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts SQL from markdown-style code blocks if present.\n",
    "    If the input looks like a list of tuples in string form, it will:\n",
    "    - Parse the list\n",
    "    - Quote all inner values\n",
    "    - Sort the list\n",
    "    - Return a string of tuples joined by commas\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "\n",
    "    # Handle SQL code block: ```sql ... ```\n",
    "    match = re.search(r\"```sql\\s*(.*?)\\s*```\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        sql = match.group(1).replace('\\n', ' ').strip()\n",
    "        return sql\n",
    "\n",
    "    # Handle list-of-tuples-as-string case\n",
    "    try:\n",
    "        # Safely evaluate the string to a Python list\n",
    "        parsed = ast.literal_eval(text)\n",
    "        if isinstance(parsed, list) and all(isinstance(item, tuple) for item in parsed):\n",
    "            # Convert all inner items to strings and quote them\n",
    "            normalized = [\n",
    "                tuple(str(x).strip() for x in row)\n",
    "                for row in parsed\n",
    "            ]\n",
    "            # Sort for consistent comparison\n",
    "            sorted_rows = sorted(normalized)\n",
    "            return \", \".join(str(row) for row in sorted_rows)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: remove brackets if it looks like a wrapped string\n",
    "    if text.startswith(\"[\") and text.endswith(\"]\"):\n",
    "        text = text[1:-1].strip().strip(\"'\\\"\")\n",
    "\n",
    "    return text.replace('\\n', ' ').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfcef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"TOGETHER_API_KEY\" not in os.environ:\n",
    "    os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass(\"yourAPIKeyHere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"yourAPIKeyHere\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84145ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOGETHER_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import ChatTogether\n",
    "\n",
    "llm = ChatTogether(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"who are you?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f2cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"togethercomputer/llama-3-70b\",\n",
    "    openai_api_base=\"https://api.together.xyz/v1\",\n",
    "    openai_api_key=\"your_together_ai_api_key\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tugberk Groq API Key\n",
    "#GROQ_API_KEY=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\n",
    "#-------------\n",
    "#GROQ_API_KEY=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\n",
    "# GROQ_API_KEY=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\n",
    "#--------Shivam\n",
    "#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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78853cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "#os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')\n",
    "#os.environ['GROQ_API_KEY'] = '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'\n",
    "\n",
    "#llm = ChatGroq(model='llama-3.3-70b-versatile')\n",
    "\n",
    "#print(llm.invoke('who are you?').content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb9366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\"sqlite:////Users/onurcanmemis/Downloads/spider_data/database/concert_singer/concert_singer.sqlite\")\n",
    "print(db.dialect)\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78742440",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tools:\n",
    "    print(i.name)\n",
    "    print(i.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e1b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = db.get_usable_table_names()\n",
    "system_message = \"\"\"\n",
    "You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct {dialect} query to run,\n",
    "then look at the results of the query and return the answer.\n",
    "You can order the results by a relevant column to return the most interesting\n",
    "examples in the database. Never query for all the columns from a specific table,\n",
    "only ask for the relevant columns given the question.\n",
    "\n",
    "You MUST double check your query before executing it. If you get an error while\n",
    "executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "database.\n",
    "\n",
    "The tables in the database is given as {table_names}. To start you should ALWAYS look at the tables and their columns in the database to see what you\n",
    "can query. Do NOT skip this step.\n",
    "\n",
    "Then you should query the schema of the most relevant tables.\n",
    "\"\"\".format(\n",
    "    dialect=\"SQLite\",\n",
    "    table_names=\", \".join(table_names)\n",
    ")\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, tools, prompt=system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_sql_and_result_from_agent_output(agent_output: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Extract the final SQL query and its returned value from LangGraph-style agent output.\n",
    "\n",
    "    Returns a dictionary with:\n",
    "        - 'gold_sql': SQL query as string\n",
    "        - 'gold_result': formatted string of tuples\n",
    "    \"\"\"\n",
    "    messages = agent_output.get(\"messages\", [])\n",
    "\n",
    "    sql_query = \"\"\n",
    "    sql_result = \"\"\n",
    "\n",
    "    for msg in messages:\n",
    "        if hasattr(msg, \"name\") and msg.name == \"sql_db_query\":\n",
    "            # This is the ToolMessage containing the SQL result\n",
    "            raw_result = msg.content\n",
    "            try:\n",
    "                parsed = ast.literal_eval(raw_result)\n",
    "                if isinstance(parsed, list) and all(isinstance(t, tuple) for t in parsed):\n",
    "                    sorted_rows = sorted(tuple(str(i).strip() for i in row) for row in parsed)\n",
    "                    sql_result = \", \".join(str(row) for row in sorted_rows)\n",
    "            except Exception as e:\n",
    "                sql_result = raw_result  # fallback to raw\n",
    "\n",
    "        elif hasattr(msg, \"tool_calls\"):\n",
    "            for tool_call in msg.tool_calls:\n",
    "                if tool_call[\"name\"] == \"sql_db_query\":\n",
    "                    sql_query = tool_call[\"args\"][\"query\"]\n",
    "\n",
    "    return {\n",
    "        \"generated_sql\": sql_query.strip(),\n",
    "        \"generated_result\": sql_result.strip()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25397190",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=agent_executor.invoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": golden_data_easy[1][\"question\"]}]},\n",
    "            config={\"recursion_limit\": 10}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6005b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_sql_and_result_from_agent_output(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17f7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = agent_executor.stream(\n",
    "    {\"messages\": [(\"user\", golden_data_easy[0][\"question\"])]},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72028f",
   "metadata": {},
   "source": [
    "## Hard Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88d8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"extracted_sql_examples_hard.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "golden_data_hard = [\n",
    "    {\"db_id\": item[\"db_id\"], \"question\": item[\"question\"], \"query\": item[\"gold_sql\"], \"result\": item[\"gold_result\"]}\n",
    "    for item in data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a621ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_data_hard[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd63867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "save_path = \"hard_answers.json\"\n",
    "\n",
    "# Load previous progress if available\n",
    "if os.path.exists(save_path):\n",
    "    with open(save_path, \"r\") as f:\n",
    "        hard_answers = json.load(f)\n",
    "else:\n",
    "    hard_answers = []\n",
    "\n",
    "start_index = len(hard_answers)\n",
    "\n",
    "# Wrap tqdm around the remaining examples\n",
    "for i in tqdm(range(start_index, len(golden_data_hard)), desc=\"Generating SQL\", unit=\"q\"):\n",
    "    item = golden_data_hard[i]\n",
    "    try:\n",
    "        print(item[\"question\"])\n",
    "\n",
    "        # Setup DB first (important: get tables *after* db is loaded)\n",
    "        db = SQLDatabase.from_uri(f\"sqlite:////Users/onurcanmemis/Downloads/spider_data/database/{item['db_id']}/{item['db_id']}.sqlite\")\n",
    "        table_names = db.get_usable_table_names()\n",
    "\n",
    "        system_message = \"\"\"\n",
    "        You are an agent designed to interact with a SQL database.\n",
    "        Given an input question, create a syntactically correct {dialect} query to run,\n",
    "        then look at the results of the query and return the answer.\n",
    "        You can order the results by a relevant column to return the most interesting\n",
    "        examples in the database. Never query for all the columns from a specific table,\n",
    "        only ask for the relevant columns given the question.\n",
    "\n",
    "        You MUST double check your query before executing it. If you get an error while\n",
    "        executing a query, rewrite the query and try again.\n",
    "\n",
    "        DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "        database.\n",
    "\n",
    "        The tables in the database is given as {table_names}. To start you should ALWAYS look at the \n",
    "        tables and their columns in the database to see what you can query. Do NOT skip this step.\n",
    "\n",
    "        Then you should query the schema of the most relevant tables.\n",
    "        \"\"\".format(\n",
    "            dialect=\"SQLite\",\n",
    "            table_names=\", \".join(table_names)\n",
    "        )\n",
    "\n",
    "        toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "        tools = toolkit.get_tools()\n",
    "        agent_executor = create_react_agent(llm, tools, prompt=system_message)\n",
    "\n",
    "        answer = agent_executor.invoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": item[\"question\"]}]},\n",
    "            config={\"recursion_limit\": 10}\n",
    "        )\n",
    "\n",
    "        generated_query = extract_sql_and_result_from_agent_output(answer)[\"generated_sql\"]\n",
    "        generated_result = extract_sql_and_result_from_agent_output(answer)[\"generated_result\"]\n",
    "\n",
    "        hard_answers.append({\n",
    "            \"db_id\": item[\"db_id\"],\n",
    "            \"question\": item[\"question\"],\n",
    "            \"generated_sql\": generated_query or \"\",\n",
    "            \"result\": generated_result or \"\",\n",
    "            \"gold_sql\": item[\"query\"],\n",
    "            \"gold_result\": item[\"result\"]\n",
    "        })\n",
    "\n",
    "        print(f\"✅ Success at index {i}\")\n",
    "        print(hard_answers[i])\n",
    "\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(hard_answers, f, indent=2)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"GRAPH_RECURSION_LIMIT\" in error_msg or \"Recursion limit\" in error_msg:\n",
    "            print(f\"⚠️ Recursion limit hit at index {i}. Skipping.\")\n",
    "            hard_answers.append({\n",
    "                \"db_id\": item[\"db_id\"],\n",
    "                \"question\": item[\"question\"],\n",
    "                \"generated_sql\": \"\",\n",
    "                \"result\": \"\",\n",
    "                \"gold_sql\": item[\"query\"]\n",
    "            })\n",
    "            print(hard_answers)\n",
    "        elif \"tool_use_failed\" in error_msg or \"table\" in error_msg.lower():\n",
    "            print(f\"⚠️ Tool failure or table issue at index {i}. Skipping.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"❌ Error at index {i}: {e}\")\n",
    "            break\n",
    "\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(hard_answers, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8d453",
   "metadata": {},
   "source": [
    "## Medium Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"extracted_sql_examples_medium.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "golden_data_medium = [\n",
    "    {\"db_id\": item[\"db_id\"], \"question\": item[\"question\"], \"query\": item[\"gold_sql\"], \"result\": item[\"gold_result\"]}\n",
    "    for item in data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17daab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_data_medium[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe7f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "save_path = \"medium_answers.json\"\n",
    "\n",
    "# Load previous progress if available\n",
    "if os.path.exists(save_path):\n",
    "    with open(save_path, \"r\") as f:\n",
    "        medium_answers = json.load(f)\n",
    "else:\n",
    "    medium_answers = []\n",
    "\n",
    "start_index = len(medium_answers)\n",
    "\n",
    "# Wrap tqdm around the remaining examples\n",
    "for i in tqdm(range(start_index, len(golden_data_medium)), desc=\"Generating SQL\", unit=\"q\"):\n",
    "    item = golden_data_medium[i]\n",
    "    try:\n",
    "        print(item[\"question\"])\n",
    "\n",
    "        # Setup DB first (important: get tables *after* db is loaded)\n",
    "        db = SQLDatabase.from_uri(f\"sqlite:////Users/onurcanmemis/Downloads/spider_data/database/{item['db_id']}/{item['db_id']}.sqlite\")\n",
    "        table_names = db.get_usable_table_names()\n",
    "\n",
    "        system_message = \"\"\"\n",
    "        You are an agent designed to interact with a SQL database.\n",
    "        Given an input question, create a syntactically correct {dialect} query to run,\n",
    "        then look at the results of the query and return the answer.\n",
    "        You can order the results by a relevant column to return the most interesting\n",
    "        examples in the database. Never query for all the columns from a specific table,\n",
    "        only ask for the relevant columns given the question.\n",
    "\n",
    "        You MUST double check your query before executing it. If you get an error while\n",
    "        executing a query, rewrite the query and try again.\n",
    "\n",
    "        DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "        database.\n",
    "\n",
    "        The tables in the database is given as {table_names}. To start you should ALWAYS look at the tables and their columns in the database to see what you\n",
    "        can query. Do NOT skip this step.\n",
    "\n",
    "        Then you should query the schema of the most relevant tables.\n",
    "        \"\"\".format(\n",
    "            dialect=\"SQLite\",\n",
    "            table_names=\", \".join(table_names)\n",
    "        )\n",
    "\n",
    "        toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "        tools = toolkit.get_tools()\n",
    "        agent_executor = create_react_agent(llm, tools, prompt=system_message)\n",
    "\n",
    "        answer = agent_executor.invoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": item[\"question\"]}]},\n",
    "            config={\"recursion_limit\": 10}\n",
    "        )\n",
    "\n",
    "        generated_query = extract_sql_and_result_from_agent_output(answer)[\"generated_sql\"]\n",
    "        generated_result = extract_sql_and_result_from_agent_output(answer)[\"generated_result\"]\n",
    "\n",
    "        medium_answers.append({\n",
    "            \"db_id\": item[\"db_id\"],\n",
    "            \"question\": item[\"question\"],\n",
    "            \"generated_sql\": generated_query or \"\",\n",
    "            \"result\": generated_result or \"\",\n",
    "            \"gold_sql\": item[\"query\"],\n",
    "            \"gold_result\": item[\"result\"]\n",
    "        })\n",
    "\n",
    "        print(f\"✅ Success at index {i}\")\n",
    "        print(medium_answers[i])\n",
    "\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(medium_answers, f, indent=2)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"GRAPH_RECURSION_LIMIT\" in error_msg or \"Recursion limit\" in error_msg:\n",
    "            print(f\"⚠️ Recursion limit hit at index {i}. Skipping.\")\n",
    "            medium_answers.append({\n",
    "                \"db_id\": item[\"db_id\"],\n",
    "                \"question\": item[\"question\"],\n",
    "                \"generated_sql\": \"\",\n",
    "                \"result\": \"\",\n",
    "                \"gold_sql\": item[\"query\"]\n",
    "            })\n",
    "            print(medium_answers)\n",
    "        elif \"tool_use_failed\" in error_msg or \"table\" in error_msg.lower():\n",
    "            print(f\"⚠️ Tool failure or table issue at index {i}. Skipping.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"❌ Error at index {i}: {e}\")\n",
    "            break\n",
    "\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(medium_answers, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ecf79",
   "metadata": {},
   "source": [
    "## Easy Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11060aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"extracted_sql_examples_easy.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "golden_data_easy = [\n",
    "    {\"db_id\": item[\"db_id\"], \"question\": item[\"question\"], \"query\": item[\"gold_sql\"], \"result\": item[\"gold_result\"]}\n",
    "    for item in data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63769426",
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_data_easy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfc3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "save_path = \"easy_answers.json\"\n",
    "\n",
    "# Load previous progress if available\n",
    "if os.path.exists(save_path):\n",
    "    with open(save_path, \"r\") as f:\n",
    "        easy_answers = json.load(f)\n",
    "else:\n",
    "    easy_answers = []\n",
    "\n",
    "start_index = len(easy_answers)\n",
    "\n",
    "# Wrap tqdm around the remaining examples\n",
    "for i in tqdm(range(start_index, len(golden_data_easy)), desc=\"Generating SQL\", unit=\"q\"):\n",
    "    item = golden_data_easy[i]\n",
    "    try:\n",
    "        print(item[\"question\"])\n",
    "        system_message = \"\"\"\n",
    "        You are an agent designed to interact with a SQL database.\n",
    "        Given an input question, create a syntactically correct {dialect} query to run,\n",
    "        then look at the results of the query and return the answer.\n",
    "        You can order the results by a relevant column to return the most interesting\n",
    "        examples in the database. Never query for all the columns from a specific table,\n",
    "        only ask for the relevant columns given the question.\n",
    "\n",
    "        You MUST double check your query before executing it. If you get an error while\n",
    "        executing a query, rewrite the query and try again.\n",
    "\n",
    "        DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "        database.\n",
    "\n",
    "        The tables in the database is given as {table_names}. To start you should ALWAYS look at the tables and their columns in the database to see what you\n",
    "        can query. Do NOT skip this step.\n",
    "\n",
    "        Then you should query the schema of the most relevant tables.\n",
    "        \"\"\".format(\n",
    "        dialect=\"SQLite\",\n",
    "        table_names=db.get_usable_table_names()\n",
    "        )\n",
    "        db = SQLDatabase.from_uri(f\"sqlite:////Users/onurcanmemis/Downloads/spider_data/database/{item['db_id']}/{item['db_id']}.sqlite\")\n",
    "        toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "        tools = toolkit.get_tools()\n",
    "        agent_executor = create_react_agent(llm, tools, prompt=system_message)\n",
    "        answer=agent_executor.invoke({\"messages\": [{\"role\": \"user\", \"content\": item[\"question\"]}]},\n",
    "                                     config={\"recursion_limit\": 10})\n",
    "        #answers.update({\"query\":extract_sql_code_block(answer.get(\"messages\")[-3].content),\"return\":extract_sql_code_block(answer.get(\"messages\")[-2].content)})\n",
    "        generated_query=extract_sql_and_result_from_agent_output(answer)[\"generated_sql\"]\n",
    "        generated_result=extract_sql_and_result_from_agent_output(answer)[\"generated_result\"]\n",
    "        easy_answers.append({\n",
    "            \"db_id\": item[\"db_id\"],\n",
    "            \"question\": item[\"question\"],\n",
    "            \"generated_sql\": generated_query or \"\",\n",
    "            \"result\": generated_result or \"\",\n",
    "            \"gold_sql\":item[\"query\"],\n",
    "            \"gold_result\":item[\"result\"]\n",
    "        })\n",
    "        print(f\"✅ Success at index {i}\")\n",
    "        print(easy_answers[i])\n",
    "\n",
    "        # Save progress after each successful query\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(easy_answers, f, indent=2)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"GRAPH_RECURSION_LIMIT\" in error_msg or \"Recursion limit\" in error_msg:\n",
    "            print(f\"⚠️ Recursion limit hit at index {i}. Skipping.\")\n",
    "            easy_answers.append({\n",
    "            \"db_id\": item[\"db_id\"],\n",
    "            \"question\": item[\"question\"],\n",
    "            \"generated_sql\": \"\",\n",
    "            \"result\": \"\"})\n",
    "            print(easy_answers[i])\n",
    "        elif \"tool_use_failed\" in error_msg or \"table\" in error_msg.lower():\n",
    "            print(f\"⚠️ Tool failure or table issue at index {i}. Skipping.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"❌ Error at index {i}: {e}\")\n",
    "            break\n",
    "\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(easy_answers, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc64b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "# Load the merged JSON file\n",
    "with open(\"easy_answers.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Utility to parse result string into list of tuples\n",
    "def parse_result_string(result_str):\n",
    "    try:\n",
    "        parsed = ast.literal_eval(f\"[{result_str}]\")  # convert comma-separated tuples into a list\n",
    "        return parsed if isinstance(parsed, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# Build prediction and gold lists\n",
    "predictions = []\n",
    "gold_data = []\n",
    "\n",
    "for item in data:\n",
    "    pred_sql = item.get(\"generated_sql\", \"\")\n",
    "    pred_result = parse_result_string(item.get(\"result\", \"\"))\n",
    "\n",
    "    gold_sql = item.get(\"gold_sql\", \"\")\n",
    "    gold_result = parse_result_string(item.get(\"gold_result\", \"\"))\n",
    "\n",
    "    predictions.append((pred_sql, pred_result))\n",
    "    gold_data.append((gold_sql, gold_result))\n",
    "\n",
    "# Check samples\n",
    "print(\"Example prediction:\", predictions[0])\n",
    "print(\"Example gold:\", gold_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d97649",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import sqlparse\n",
    "\n",
    "def normalize_sql(sql):\n",
    "    sql = sql.strip().rstrip(';')\n",
    "    parsed = sqlparse.format(sql, keyword_case='lower', strip_comments=True, reindent=True)\n",
    "    return \" \".join(parsed.strip().split()).lower()\n",
    "\n",
    "def normalize_result(result):\n",
    "    if not result or not isinstance(result, list):\n",
    "        return set()\n",
    "\n",
    "    normalized = set()\n",
    "    for row in result:\n",
    "        if row is None:\n",
    "            continue  # skip invalid rows\n",
    "        try:\n",
    "            normalized.add(tuple(str(item).strip() for item in row))\n",
    "        except Exception:\n",
    "            continue  # skip malformed rows\n",
    "\n",
    "    return normalized\n",
    "def extract_components(sql):\n",
    "    parsed = sqlparse.parse(sql)\n",
    "    if not parsed:\n",
    "        return {\"select\": set(), \"from\": set(), \"where\": set()}\n",
    "    stmt = parsed[0]\n",
    "\n",
    "    select_tokens = set()\n",
    "    from_tokens = set()\n",
    "    where_tokens = set()\n",
    "\n",
    "    is_select = False\n",
    "    is_from = False\n",
    "    is_where = False\n",
    "\n",
    "    for token in stmt.tokens:\n",
    "        if token.is_group:\n",
    "            for subtoken in token.flatten():\n",
    "                tval = subtoken.value.lower().strip()\n",
    "                if tval in (\"select\", \"from\", \"where\"):\n",
    "                    is_select = tval == \"select\"\n",
    "                    is_from = tval == \"from\"\n",
    "                    is_where = tval == \"where\"\n",
    "                    continue\n",
    "                if is_select and subtoken.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Wildcard):\n",
    "                    select_tokens.add(tval)\n",
    "                elif is_from and subtoken.ttype in (sqlparse.tokens.Name,):\n",
    "                    from_tokens.add(tval)\n",
    "                elif is_where and subtoken.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Literal.Number.Integer, sqlparse.tokens.Operator.Comparison):\n",
    "                    where_tokens.add(tval)\n",
    "        else:\n",
    "            tval = token.value.lower().strip()\n",
    "            if tval in (\"select\", \"from\", \"where\"):\n",
    "                is_select = tval == \"select\"\n",
    "                is_from = tval == \"from\"\n",
    "                is_where = tval == \"where\"\n",
    "                continue\n",
    "            if is_select and token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Wildcard):\n",
    "                select_tokens.add(tval)\n",
    "            elif is_from and token.ttype in (sqlparse.tokens.Name,):\n",
    "                from_tokens.add(tval)\n",
    "            elif is_where and token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Literal.Number.Integer, sqlparse.tokens.Operator.Comparison):\n",
    "                where_tokens.add(tval)\n",
    "\n",
    "    return {\"select\": select_tokens, \"from\": from_tokens, \"where\": where_tokens}\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    if not set1 and not set2:\n",
    "        return 1.0\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union > 0 else 0\n",
    "def evaluate_predictions(\n",
    "    predictions: List[Tuple[str, List[Tuple]]],\n",
    "    gold_data: List[Tuple[str, List[Tuple]]]\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a list of predicted SQL queries and their results against gold SQL queries and results.\n",
    "\n",
    "    Each element in the predictions and gold_data lists is a tuple:\n",
    "    (sql_query: str, result: List[Tuple])\n",
    "\n",
    "    Returns:\n",
    "    A dictionary with evaluation metrics.\n",
    "    \"\"\"\n",
    "    exact_match_count = 0\n",
    "    execution_match_count = 0\n",
    "    total = len(predictions)\n",
    "\n",
    "    jaccard_scores = {\n",
    "        \"select\": 0.0,\n",
    "        \"from\": 0.0,\n",
    "        \"where\": 0.0\n",
    "    }\n",
    "\n",
    "    for (pred_sql, pred_result), (gold_sql, gold_result) in zip(predictions, gold_data):\n",
    "        norm_pred_sql = normalize_sql(pred_sql)\n",
    "        norm_gold_sql = normalize_sql(gold_sql)\n",
    "\n",
    "        norm_pred_result = normalize_result(pred_result)\n",
    "        norm_gold_result = normalize_result(gold_result)\n",
    "\n",
    "        if norm_pred_sql == norm_gold_sql:\n",
    "            exact_match_count += 1\n",
    "\n",
    "        if norm_pred_result == norm_gold_result:\n",
    "            execution_match_count += 1\n",
    "\n",
    "        pred_components = extract_components(norm_pred_sql)\n",
    "        gold_components = extract_components(norm_gold_sql)\n",
    "\n",
    "        for key in jaccard_scores.keys():\n",
    "            jaccard_scores[key] += jaccard_similarity(pred_components.get(key, set()), gold_components.get(key, set()))\n",
    "\n",
    "    # Average jaccard scores\n",
    "    for key in jaccard_scores:\n",
    "        jaccard_scores[key] /= total\n",
    "\n",
    "    metrics = {\n",
    "        \"total\": total,\n",
    "        \"exact_match_accuracy\": exact_match_count / total if total else 0.0,\n",
    "        \"execution_match_accuracy\": execution_match_count / total if total else 0.0,\n",
    "        \"select_jaccard\": jaccard_scores[\"select\"],\n",
    "        \"from_jaccard\": jaccard_scores[\"from\"],\n",
    "        \"where_jaccard\": jaccard_scores[\"where\"]\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea2c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "# Load the merged JSON file\n",
    "with open(\"hard_answers.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Utility to parse result string into list of tuples\n",
    "def parse_result_string(result_str):\n",
    "    try:\n",
    "        parsed = ast.literal_eval(f\"[{result_str}]\")  # convert comma-separated tuples into a list\n",
    "        return parsed if isinstance(parsed, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# Build prediction and gold lists\n",
    "hard_predictions = []\n",
    "hard_gold_data = []\n",
    "\n",
    "for item in data:\n",
    "    pred_sql = item.get(\"generated_sql\", \"\")\n",
    "    pred_result = parse_result_string(item.get(\"result\", \"\"))\n",
    "\n",
    "    gold_sql = item.get(\"gold_sql\", \"\")\n",
    "    gold_result = parse_result_string(item.get(\"gold_result\", \"\"))\n",
    "\n",
    "    hard_predictions.append((pred_sql, pred_result))\n",
    "    hard_gold_data.append((gold_sql, gold_result))\n",
    "\n",
    "# Check samples\n",
    "print(\"Example prediction:\", hard_predictions[0])\n",
    "print(\"Example gold:\", hard_gold_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_predictions(hard_predictions, hard_gold_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1841f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "# Load the merged JSON file\n",
    "with open(\"medium_answers.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Utility to parse result string into list of tuples\n",
    "def parse_result_string(result_str):\n",
    "    try:\n",
    "        parsed = ast.literal_eval(f\"[{result_str}]\")  # convert comma-separated tuples into a list\n",
    "        return parsed if isinstance(parsed, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# Build prediction and gold lists\n",
    "medium_predictions = []\n",
    "medium_gold_data = []\n",
    "\n",
    "for item in data:\n",
    "    pred_sql = item.get(\"generated_sql\", \"\")\n",
    "    pred_result = parse_result_string(item.get(\"result\", \"\"))\n",
    "\n",
    "    gold_sql = item.get(\"gold_sql\", \"\")\n",
    "    gold_result = parse_result_string(item.get(\"gold_result\", \"\"))\n",
    "\n",
    "    medium_predictions.append((pred_sql, pred_result))\n",
    "    medium_gold_data.append((gold_sql, gold_result))\n",
    "\n",
    "# Check samples\n",
    "print(\"Example prediction:\", medium_predictions[0])\n",
    "print(\"Example gold:\", medium_gold_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_predictions(medium_predictions, medium_gold_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b01668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "# Load the merged JSON file\n",
    "with open(\"easy_answers.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Utility to parse result string into list of tuples\n",
    "def parse_result_string(result_str):\n",
    "    try:\n",
    "        parsed = ast.literal_eval(f\"[{result_str}]\")  # convert comma-separated tuples into a list\n",
    "        return parsed if isinstance(parsed, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# Build prediction and gold lists\n",
    "easy_predictions = []\n",
    "easy_gold_data = []\n",
    "\n",
    "for item in data:\n",
    "    pred_sql = item.get(\"generated_sql\", \"\")\n",
    "    pred_result = parse_result_string(item.get(\"result\", \"\"))\n",
    "\n",
    "    gold_sql = item.get(\"gold_sql\", \"\")\n",
    "    gold_result = parse_result_string(item.get(\"gold_result\", \"\"))\n",
    "\n",
    "    easy_predictions.append((pred_sql, pred_result))\n",
    "    easy_gold_data.append((gold_sql, gold_result))\n",
    "\n",
    "# Check samples\n",
    "print(\"Example prediction:\", easy_predictions[0])\n",
    "print(\"Example gold:\", easy_gold_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_predictions(easy_predictions, easy_gold_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d0859",
   "metadata": {},
   "source": [
    "## Logic Equivalence Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f34c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Helper function\n",
    "def extract_question_and_result(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    current = {}\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"Question:\"):\n",
    "            current[\"question\"] = line.replace(\"Question:\", \"\").strip()\n",
    "        elif line.startswith(\"Execution Result:\"):\n",
    "            current[\"execution_result\"] = line.replace(\"Execution Result:\", \"\").strip()\n",
    "            if \"question\" in current:  # Ensure both parts exist\n",
    "                data.append(current)\n",
    "            current = {}  # Reset for next instance\n",
    "\n",
    "    return data\n",
    "\n",
    "# Process each difficulty file\n",
    "easy_data = extract_question_and_result(\"easy.txt\")\n",
    "medium_data = extract_question_and_result(\"medium.txt\")\n",
    "hard_data = extract_question_and_result(\"hard.txt\")\n",
    "\n",
    "# Write to JSON\n",
    "with open(\"questions_easy.json\", \"w\") as f:\n",
    "    json.dump(easy_data, f, indent=2)\n",
    "\n",
    "with open(\"questions_medium.json\", \"w\") as f:\n",
    "    json.dump(medium_data, f, indent=2)\n",
    "\n",
    "with open(\"questions_hard.json\", \"w\") as f:\n",
    "    json.dump(hard_data, f, indent=2)\n",
    "\n",
    "print(\"✅ JSON files written with question and execution_result.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"questions_easy.json\", \"r\") as f:\n",
    "    easy_data = json.load(f)\n",
    "\n",
    "with open(\"questions_medium.json\", \"r\") as f:\n",
    "    medium_data = json.load(f)\n",
    "\n",
    "with open(\"questions_hard.json\", \"r\") as f:\n",
    "    hard_data = json.load(f)\n",
    "\n",
    "print(\"Number of easy questions:\", len(easy_data))\n",
    "print(\"Number of medium questions:\", len(medium_data))\n",
    "print(\"Number of hard questions:\", len(hard_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_execution=[]\n",
    "medium_execution=[]\n",
    "hard_execution=[]\n",
    "\n",
    "for item in easy_predictions:\n",
    "    easy_execution.append(item[1])\n",
    "\n",
    "for item in medium_predictions:\n",
    "    medium_execution.append(item[1])\n",
    "\n",
    "for item in hard_predictions:\n",
    "    hard_execution.append(item[1])\n",
    "\n",
    "easy_execution=[str(item) for item in easy_execution]\n",
    "medium_execution=[str(item) for item in medium_execution]\n",
    "hard_execution=[str(item) for item in hard_execution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_easy=[]\n",
    "custom_medium=[]\n",
    "custom_hard=[]\n",
    "\n",
    "for item in easy_data:\n",
    "    custom_easy.append(item[\"execution_result\"].replace(\"{\", \"[\").replace(\"}\", \"]\"))\n",
    "\n",
    "for item in medium_data:\n",
    "    custom_medium.append(item[\"execution_result\"].replace(\"{\", \"[\").replace(\"}\", \"]\"))\n",
    "\n",
    "for item in hard_data:\n",
    "    custom_hard.append(item[\"execution_result\"].replace(\"{\", \"[\").replace(\"}\", \"]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def normalize_result_string(result_str):\n",
    "    \"\"\"\n",
    "    Converts a result string like \"[('Alice',), ('Bob',)]\" or \"('Alice',), ('Bob',)\" into a set of tuples.\n",
    "    Handles empty strings and malformed inputs gracefully.\n",
    "    \"\"\"\n",
    "    if not result_str.strip():\n",
    "        return set()\n",
    "\n",
    "    try:\n",
    "        # Ensure it's parsable as a list: wrap if not\n",
    "        if not result_str.strip().startswith(\"[\"):\n",
    "            result_str = \"[\" + result_str + \"]\"\n",
    "\n",
    "        parsed = ast.literal_eval(result_str)\n",
    "        if isinstance(parsed, list):\n",
    "            return set(tuple(str(x).strip() for x in row) for row in parsed)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return set()\n",
    "\n",
    "def logic_equivalence_score(langchain_results, agentic_results):\n",
    "    assert len(langchain_results) == len(agentic_results), \"Mismatched result lengths\"\n",
    "\n",
    "    total = len(langchain_results)\n",
    "    equivalent_count = 0\n",
    "\n",
    "    for l_result, a_result in zip(langchain_results, agentic_results):\n",
    "        if normalize_result_string(l_result) == normalize_result_string(a_result):\n",
    "            equivalent_count += 1\n",
    "\n",
    "    return equivalent_count / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd985c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_equivalence_score(easy_execution,custom_easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_equivalence_score(medium_execution,custom_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_equivalence_score(hard_execution,custom_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf84fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
