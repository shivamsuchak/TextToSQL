{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "487435a3",
      "metadata": {
        "id": "487435a3"
      },
      "source": [
        "# Natural Language to SQL for Snowflake\n",
        "\n",
        "This notebook demonstrates how to convert natural language questions to SQL queries for Snowflake databases using LangChain, GROQ (LLaMA models), and other tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f26ef47f",
      "metadata": {
        "id": "f26ef47f"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q langchain-community langchain-core langgraph langchain-groq snowflake-connector-python dotenv pandas sqlglot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67149145",
      "metadata": {
        "id": "67149145"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import snowflake.connector\n",
        "from dotenv import load_dotenv\n",
        "from langchain_groq import ChatGroq\n",
        "from pydantic import BaseModel, Field\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "\n",
        "# Load from .env\n",
        "# load_dotenv()\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1d687f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af1d687f",
        "outputId": "2911dd41-f58e-4bf4-b1dc-32ff4a1ef9fc"
      },
      "outputs": [],
      "source": [
        "def load_credentials(file_path):\n",
        "    \"\"\"\n",
        "    Load Snowflake credentials from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the JSON file containing credentials\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with Snowflake credentials\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "# Path to credentials file\n",
        "# credentials_path = \"yourcredentialsfilepath/snowflake_credential.json\"\n",
        "\n",
        "# Load credentials\n",
        "# credentials = load_credentials(credentials_path)\n",
        "\n",
        "credentials = {\"user\": \"shivamsuchak997\",\n",
        "    \"password\": \"Rickofiz@99796\",\n",
        "    \"account\": \"RSRSBDK-YDB67606\"}\n",
        "\n",
        "# Connect to Snowflake\n",
        "conn = snowflake.connector.connect(\n",
        "    user=credentials['user'],\n",
        "    password=credentials['password'],\n",
        "    account=credentials['account']\n",
        ")\n",
        "\n",
        "print(f\"Successfully connected to Snowflake!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33c216e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33c216e8",
        "outputId": "007e10f5-e08b-44d8-d83a-727a3cb67b1d"
      },
      "outputs": [],
      "source": [
        "# Create a cursor object\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# List databases\n",
        "cursor.execute(\"SHOW DATABASES\")\n",
        "\n",
        "# Fetch all results\n",
        "results = cursor.fetchall()\n",
        "\n",
        "# Get column names\n",
        "columns = [desc[0] for desc in cursor.description]\n",
        "\n",
        "# Convert to DataFrame\n",
        "database_df = pd.DataFrame(results, columns=columns)\n",
        "\n",
        "# Print available databases\n",
        "print(\"Available databases:\")\n",
        "print(database_df[['name', 'created_on']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79a94f9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79a94f9c",
        "outputId": "8c14f1ba-ccf7-4c29-fd1a-36e8994a6699"
      },
      "outputs": [],
      "source": [
        "# Select a database to use for this example\n",
        "# You can modify this to use any database from the list\n",
        "selected_database = \"ADVENTUREWORKS\"  # Replace with your desired database from the available list\n",
        "\n",
        "# Use the selected database\n",
        "cursor.execute(f\"USE DATABASE {selected_database}\")\n",
        "print(f\"Using database: {selected_database}\")\n",
        "\n",
        "# List all schemas in the selected database\n",
        "cursor.execute(\"SHOW SCHEMAS\")\n",
        "schemas_results = cursor.fetchall()\n",
        "schemas_columns = [desc[0] for desc in cursor.description]\n",
        "schemas_df = pd.DataFrame(schemas_results, columns=schemas_columns)\n",
        "print(\"\\nAvailable schemas:\")\n",
        "print(schemas_df[['name', 'created_on']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc45f32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bc45f32",
        "outputId": "ec39bd6a-c945-419d-f8f9-00b22ceae8f1"
      },
      "outputs": [],
      "source": [
        "# Select a schema to use\n",
        "selected_schema = schemas_df['name'].iloc[0]  # Use the first schema by default\n",
        "cursor.execute(f\"USE SCHEMA {selected_schema}\")\n",
        "print(f\"Using schema: {selected_schema}\")\n",
        "\n",
        "# List all tables in the selected schema\n",
        "cursor.execute(\"SHOW TABLES\")\n",
        "tables_results = cursor.fetchall()\n",
        "tables_columns = [desc[0] for desc in cursor.description]\n",
        "tables_df = pd.DataFrame(tables_results, columns=tables_columns)\n",
        "print(\"\\nAvailable tables:\")\n",
        "print(tables_df[['name', 'created_on']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "464ef344",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "464ef344",
        "outputId": "9f15ab22-5d5f-406e-f25e-1cce286d49a7"
      },
      "outputs": [],
      "source": [
        "# Function to get schema information for a table\n",
        "def get_table_schema(table_name):\n",
        "    cursor.execute(f\"DESCRIBE TABLE {table_name}\")\n",
        "    desc_results = cursor.fetchall()\n",
        "    desc_columns = [desc[0] for desc in cursor.description]\n",
        "    result_df = pd.DataFrame(desc_results, columns=desc_columns)\n",
        "\n",
        "    # Ensure we preserve the exact case from Snowflake for column names\n",
        "    # This is critical because Snowflake is case-sensitive when querying\n",
        "    if 'name' in result_df.columns:\n",
        "        # Make sure we're getting the exact case representation from Snowflake\n",
        "        cursor.execute(f\"SELECT column_name FROM information_schema.columns WHERE table_name = '{table_name.upper()}'\")\n",
        "        column_names_results = cursor.fetchall()\n",
        "\n",
        "        # If we got results from information_schema, use those exact names\n",
        "        if column_names_results:\n",
        "            # Create a mapping of uppercase names to actual case names\n",
        "            case_mapping = {name[0].upper(): name[0] for name in column_names_results}\n",
        "\n",
        "            # Apply the case mapping to the result dataframe\n",
        "            result_df['original_name'] = result_df['name'].apply(\n",
        "                lambda x: case_mapping.get(x.upper(), x) if isinstance(x, str) else x\n",
        "            )\n",
        "            # Use the original case for display but keep the name column for other operations\n",
        "            result_df['display_name'] = result_df['original_name']\n",
        "\n",
        "    return result_df\n",
        "\n",
        "# Collect schema information for all tables\n",
        "schema_info = \"# SNOWFLAKE CASE SENSITIVITY NOTICE:\\n\"\n",
        "schema_info += \"# In Snowflake, identifiers (table names, column names) are case-insensitive by default\\n\"\n",
        "schema_info += \"# but are stored in UPPERCASE unless quoted. When writing SQL, use the exact case shown below\\n\"\n",
        "schema_info += \"# or enclose identifiers in double quotes if using lowercase (e.g., \\\"columnname\\\").\\n\\n\"\n",
        "\n",
        "for table in tables_df['name'].values:\n",
        "    actual_table_name = table  # Keep original case from Snowflake\n",
        "    schema_info += f\"Table: {actual_table_name}\\n\"\n",
        "    table_schema = get_table_schema(table)\n",
        "\n",
        "    # Preserve the exact column names and types\n",
        "    column_info = []\n",
        "    for idx, row in table_schema.iterrows():\n",
        "        # Use display_name if available, otherwise fall back to name\n",
        "        if 'display_name' in table_schema.columns:\n",
        "            col_name = row['display_name']\n",
        "        else:\n",
        "            col_name = row['name']\n",
        "        col_type = row['type']\n",
        "        column_info.append(f\"{col_name:<30} {col_type}\")\n",
        "\n",
        "    schema_info += \"\\n\".join(column_info) + \"\\n\\n\"\n",
        "\n",
        "print(\"Schema information collected for all tables.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a3ecc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76a3ecc0",
        "outputId": "b93666b7-a245-4d86-e549-b13787e33674"
      },
      "outputs": [],
      "source": [
        "# Setup the language model\n",
        "llm = ChatGroq(model='llama3-70b-8192') # llama3-70b-8192, llama-3.3-70b-versatile # Use appropriate model name\n",
        "print(llm.invoke('who are you?').content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d7e528",
      "metadata": {
        "id": "e1d7e528"
      },
      "outputs": [],
      "source": [
        "# Initial state definition\n",
        "class AgentState(TypedDict):\n",
        "    question: str\n",
        "    sql_query: str\n",
        "    query_result: str\n",
        "    query_rows: list\n",
        "    attempts: int\n",
        "    relevance: str\n",
        "    final_answer: str\n",
        "    sql_error: bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7396342f",
      "metadata": {
        "id": "7396342f"
      },
      "outputs": [],
      "source": [
        "# Agent 1: Determines if the user NL-input is relevant to the db schema\n",
        "class CheckRelevance(BaseModel):\n",
        "    relevance: str = Field(\n",
        "        description=\"Indicates whether the question is related to the database schema. 'relevant' or 'not_relevant'.\"\n",
        "    )\n",
        "\n",
        "def check_relevance(state: AgentState):\n",
        "    question = state[\"question\"]\n",
        "    print(f\"Checking relevance of the question: {question}\")\n",
        "    system = \"\"\"You are a highly skilled SQL expert. Your task is to evaluate whether a given natural language question is relevant to a database based on its schema.\n",
        "\n",
        "    Use the schema below to determine whether the question can reasonably be answered using the available tables and columns.\n",
        "\n",
        "    ---\n",
        "    Schema:\n",
        "    {schema}\n",
        "    ---\n",
        "\n",
        "    Instructions:\n",
        "    1. Carefully read the user's question.\n",
        "    2. Check whether the schema contains the necessary tables and columns to answer the question.\n",
        "    3. If the question can be answered using the schema, respond with **\"relevant\"**.\n",
        "    4. If the schema lacks the necessary information, respond with **\"not_relevant\"**.\n",
        "    5. Your response must be either **\"relevant\"** or **\"not_relevant\"** only—do not explain or elaborate.\n",
        "\n",
        "    Output Format:\n",
        "    relevant\n",
        "    or\n",
        "    not_relevant\n",
        "    \"\"\"\n",
        "    human = f\"Question: {question}\"\n",
        "    check_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system),\n",
        "            (\"human\", human),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    structured_llm = llm.with_structured_output(CheckRelevance)\n",
        "    relevance_checker = check_prompt | structured_llm\n",
        "    try:\n",
        "      relevance = relevance_checker.invoke({'schema': schema_info})\n",
        "      state[\"relevance\"] = relevance.relevance.lower().strip()\n",
        "      print(f\"Relevance determined: {state['relevance']}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error during relevance check: {e}\")\n",
        "      state[\"relevance\"] = \"not_relevant\"\n",
        "      state[\"sql_error\"] = True\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a63f31f9",
      "metadata": {
        "id": "a63f31f9"
      },
      "outputs": [],
      "source": [
        "# Agent 2: Converts natural language to SQL queries\n",
        "class ConvertToSQL(BaseModel):\n",
        "    sql_query: str = Field(\n",
        "        description=\"The SQL query corresponding to the user's natural language question.\"\n",
        "    )\n",
        "\n",
        "def convert_nl_to_sql(state: AgentState):\n",
        "    question = state[\"question\"]\n",
        "    print(f\"Converting question to SQL for user: {question}\")\n",
        "    system = \"\"\"\n",
        "    You are a highly skilled SQL generation assistant for Snowflake. Your task is to convert a user's natural language question into a valid, syntactically correct, and semantically meaningful SQL query using Snowflake SQL dialect.\n",
        "\n",
        "    Follow these strict rules:\n",
        "\n",
        "    1. **Use only the tables and columns provided in the schema below**. Do not invent or reference tables/columns that are not explicitly listed.\n",
        "    2. **Be extremely careful with case sensitivity**. Snowflake identifiers are case-insensitive by default but stored in UPPERCASE unless quoted.\n",
        "      - Use the EXACT CASE as shown in the schema for table and column names\n",
        "      - Always enclose column names in DUBLE QUOTES (e.g., \"column_name\") but NOT table names with exact case, for example:\n",
        "          > SELECT \"column_name\" FROM TABLE_NAME;\n",
        "          > SELECT x.\"column_1\" AS x_name, y.\"column_2\" AS y_name FROM TABLENAME1 x JOIN TABLENAME2 y ON x.\"id\" = y.\"id\";\n",
        "\n",
        "      - The database is highly case sensitive. Make sure to use the **EXACT** case as shown in the schema.\n",
        "      - DO NOT use mixed case or assume case insensitivity\n",
        "      - For columns with complex names like \"CULTUREID\" or compound words, maintain the EXACT case shown in the schema\n",
        "      - When in doubt, add double quotes around column names (e.g., \"CULTUREID\") to ensure precise matching\n",
        "    3. **Understand the relationships between tables** and use JOINs accordingly where appropriate.\n",
        "    4. **Avoid using `SELECT *`**. Instead, return only the specific columns that are relevant to answering the user's question.\n",
        "    5. Use appropriate **filters, sorting, and grouping** based on the user's intent (e.g., time ranges, categories, totals).\n",
        "    6. If necessary, use **aggregations** (COUNT, AVG, MAX, etc.) when the question asks for summaries or statistics.\n",
        "    7. Maintain clarity and simplicity. Prioritize correctness over cleverness.\n",
        "\n",
        "    Before generating the SQL:\n",
        "    - Carefully analyze the user's question.\n",
        "    - Check the exact spelling and case of all tables and columns in the schema.\n",
        "    - Infer any implicit intent (e.g., filtering, ordering) only if it logically follows from the question.\n",
        "    - Never assume facts that are not supported by the schema or the question.\n",
        "\n",
        "    Schema:\n",
        "    {table_info}\n",
        "\n",
        "    Now, generate the SQL query that answers the following user question:\n",
        "    \"\"\"\n",
        "\n",
        "    convert_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system),\n",
        "            (\"human\", \"Question: {question}\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    structured_llm = llm.with_structured_output(ConvertToSQL)\n",
        "    sql_generator = convert_prompt | structured_llm\n",
        "    try:\n",
        "      result = sql_generator.invoke({\"question\": question, \"table_info\": schema_info})\n",
        "      state[\"sql_query\"] = result.sql_query.strip()\n",
        "    except Exception as e:\n",
        "      print(f\"Failed to generate SQL: {e}\")\n",
        "      state[\"sql_query\"] = \"\"\n",
        "      state[\"sql_error\"] = True\n",
        "    print(f\"Generated SQL query: {state['sql_query']}\")\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3045bc2",
      "metadata": {
        "id": "e3045bc2"
      },
      "outputs": [],
      "source": [
        "# Agent 3: Executes generated SQL query\n",
        "def execute_query(state: AgentState):\n",
        "    \"\"\"Execute SQL query and update state based on outcome.\"\"\"\n",
        "    sql_query = state[\"sql_query\"]\n",
        "    print(f\"Executing SQL query: {sql_query}\")\n",
        "\n",
        "    try:\n",
        "        # Execute the query\n",
        "        cursor.execute(sql_query)\n",
        "        results = cursor.fetchall()\n",
        "\n",
        "        # Get column names\n",
        "        columns = [desc[0] for desc in cursor.description]\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(results, columns=columns)\n",
        "\n",
        "        if df.empty:\n",
        "            state[\"query_result\"] = \"No data found for the specified query.\"\n",
        "        else:\n",
        "            state[\"query_result\"] = df.to_string()\n",
        "\n",
        "        state[\"sql_error\"] = False\n",
        "    except Exception as e:\n",
        "        print(f\"Error during SQL execution: {e}\")\n",
        "        state[\"sql_error\"] = True\n",
        "        state[\"query_result\"] = str(e)\n",
        "\n",
        "        # Check for case sensitivity errors in the error message\n",
        "        error_msg = str(e).lower()\n",
        "        if (\"invalid identifier\" in error_msg or \"object does not exist\" in error_msg):\n",
        "            # Add specific info about case sensitivity issues to help with regeneration\n",
        "            state[\"query_result\"] += \"\\n\\nThis appears to be a case sensitivity issue. Remember that in Snowflake:\\n\"\n",
        "            state[\"query_result\"] += \"1. Identifiers are case-insensitive but stored in UPPERCASE unless quoted\\n\"\n",
        "            state[\"query_result\"] += \"2. Use the EXACT CASE as shown in the schema\\n\"\n",
        "            state[\"query_result\"] += \"3. When using identifiers exactly as shown in the schema, quote them with double quotes\\n\"\n",
        "            state[\"query_result\"] += \"4. For complex table or column names like PRODUCTMODELPRODUCTDESCRIPTIONCULTURE or CULTUREID, use double quotes\\n\"\n",
        "            state[\"query_result\"] += \"5. Example: SELECT \\\"CULTUREID\\\" FROM \\\"PRODUCTMODELPRODUCTDESCRIPTIONCULTURE\\\" WHERE \\\"CULTUREID\\\" = 'en'\"\n",
        "\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62a19296",
      "metadata": {
        "id": "62a19296"
      },
      "outputs": [],
      "source": [
        "# Agent 4: Based on SQL result, generates NL answer\n",
        "def generate_answer(state: AgentState):\n",
        "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
        "    template = PromptTemplate.from_template(\n",
        "    \"\"\"You are an intelligent data assistant. Your task is to help answer the user's natural language question by using the provided SQL query and its result.\n",
        "\n",
        "    You will be given:\n",
        "    1. The original user question.\n",
        "    2. The SQL query that was generated to answer the question.\n",
        "    3. The result returned by executing that SQL query.\n",
        "\n",
        "    Use this information to provide a helpful, clear, and concise answer to the user's question. If the result is empty or insufficient to answer the question confidently, respond accordingly.\n",
        "\n",
        "    ---\n",
        "    Question: {question}\n",
        "    SQL Query: {sql_query}\n",
        "    SQL Result: {query_result}\n",
        "    ---\n",
        "\n",
        "    Final Answer:\"\"\")\n",
        "\n",
        "    llm_chain = template | llm | StrOutputParser()\n",
        "    answer = llm_chain.invoke({\n",
        "        \"question\": state[\"question\"],\n",
        "        \"sql_query\": state[\"sql_query\"],\n",
        "        \"query_result\": state[\"query_result\"]\n",
        "    })\n",
        "    state[\"final_answer\"] = answer\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f248391a",
      "metadata": {
        "id": "f248391a"
      },
      "outputs": [],
      "source": [
        "# Agent 5: Generates funny response if the user's query is not relevant to the db\n",
        "def generate_funny_response(state: AgentState):\n",
        "    print(\"Generating a funny response for an unrelated question.\")\n",
        "    system = \"\"\"\n",
        "    You are a witty, charming, and funny assistant whose job is to entertain users when they ask questions unrelated to the database or when no relevant answer can be provided.\n",
        "\n",
        "    Your responses should:\n",
        "    - Be playful and light-hearted.\n",
        "    - Stay appropriate and friendly.\n",
        "    - Acknowledge that the question isn't answerable via the database.\n",
        "    - Gently steer the user back on track with a smile (figuratively).\n",
        "\n",
        "    You are not required to be helpful — just be delightfully unhelpful in a clever way.\n",
        "    \"\"\"\n",
        "\n",
        "    human_message = f\"\"\"\n",
        "    The user asked a question that is unrelated to the database:\n",
        "    '{state['question']}'\n",
        "    Craft a humorous and creative response.\"\"\"\n",
        "\n",
        "    funny_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system),\n",
        "        (\"human\", human_message),\n",
        "    ])\n",
        "\n",
        "    funny_response = funny_prompt | llm | StrOutputParser()\n",
        "    message = funny_response.invoke({})\n",
        "    state[\"final_answer\"] = message\n",
        "    print(\"Generated funny response.\")\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f26c52",
      "metadata": {
        "id": "93f26c52"
      },
      "outputs": [],
      "source": [
        "# Agent 6: Rewrites the question if there isn't enough info\n",
        "class RewrittenQuestion(BaseModel):\n",
        "    question: str = Field(description=\"The rewritten question.\")\n",
        "\n",
        "def regenerate_query(state: AgentState):\n",
        "    question = state[\"question\"]\n",
        "    print(\"Regenerating the SQL query by rewriting the question.\")\n",
        "    system = \"\"\"\n",
        "    You are an expert in SQL and natural language understanding for Snowflake databases.\n",
        "\n",
        "    Your task is to **rewrite a user's natural language question** so that:\n",
        "    - It is clear, complete, and unambiguous.\n",
        "    - It is optimized to be converted into a precise and valid SQL query for Snowflake.\n",
        "    - All necessary details (e.g. filters, relationships between tables, required joins, and any implied logic) are included.\n",
        "    - The reformulated version preserves the intent and meaning of the original question but improves its structure for programmatic interpretation.\n",
        "\n",
        "    CRITICAL: Snowflake has specific case sensitivity rules:\n",
        "    - Table and column names are case-insensitive by default but stored in UPPERCASE unless quoted\n",
        "    - Always use the EXACT CASE as shown in the schema\n",
        "    - Example: If schema shows \"PRODUCTMODELPRODUCTDESCRIPTIONCULTURE\" table with \"CULTUREID\" column, use exactly that case\n",
        "    - For combined or compound words like \"CULTUREID\" or \"PRODUCTMODELPRODUCTDESCRIPTION\", maintain the EXACT case shown\n",
        "    - Never mix up the case of identifiers (avoid \"Customerid\", \"CustomerID\", etc.)\n",
        "    - When in doubt, suggest using double quotes around identifiers (e.g., \"CULTUREID\")\n",
        "\n",
        "    Avoid making assumptions not supported by the original question or schema.\n",
        "    \"\"\"\n",
        "\n",
        "    rewrite_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Original Question: {question}\\n\\nRewrite this question to make it clearer and more suitable for SQL generation, including all relevant details and ensuring proper case handling for Snowflake identifiers.\")\n",
        "    ])\n",
        "\n",
        "    structured_llm = llm.with_structured_output(RewrittenQuestion)\n",
        "    rewriter = rewrite_prompt | structured_llm\n",
        "\n",
        "    try:\n",
        "        rewritten = rewriter.invoke({\"question\": question})\n",
        "        state[\"question\"] = rewritten.question  # Update the question in state\n",
        "        state[\"attempts\"] = state.get(\"attempts\", 0) + 1\n",
        "        print(f\"Rewritten question: {state['question']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error rewriting question: {e}\")\n",
        "        # If we couldn't rewrite, increment attempts but keep original question\n",
        "        state[\"attempts\"] = state.get(\"attempts\", 0) + 1\n",
        "\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7327a0bd",
      "metadata": {
        "id": "7327a0bd"
      },
      "outputs": [],
      "source": [
        "# Conditional nodes\n",
        "def end_max_iter(state: AgentState):\n",
        "    print(\"Maximum attempts reached. Ending the workflow.\")\n",
        "    state[\"query_result\"] = \"Please try again with a more specific question.\"\n",
        "    return state\n",
        "\n",
        "def router(state: AgentState):\n",
        "    print(\"Routing based on relevance...\")\n",
        "    if state[\"relevance\"].lower() == \"relevant\":\n",
        "        return \"convert_to_sql\"\n",
        "    else:\n",
        "        return \"generate_funny_response\"\n",
        "\n",
        "def check_attempts(state: AgentState):\n",
        "    print(f\"Attempt #{state['attempts']}\")\n",
        "    if state[\"attempts\"] < 2:\n",
        "        return \"convert_to_sql\"\n",
        "    else:\n",
        "        return \"end_max_iter\"\n",
        "\n",
        "def execute_sql(state: AgentState):\n",
        "    print(\"Routing based on SQL execution result...\")\n",
        "    if not state.get(\"sql_error\", False):\n",
        "        return \"generate_answer\"\n",
        "    else:\n",
        "        return \"regenerate_query\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa7f2b82",
      "metadata": {
        "id": "aa7f2b82"
      },
      "outputs": [],
      "source": [
        "# Constructing the Graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"check_relevance\", check_relevance)\n",
        "workflow.add_node(\"convert_to_sql\", convert_nl_to_sql)\n",
        "workflow.add_node(\"execute_sql\", execute_query)\n",
        "workflow.add_node(\"generate_answer\", generate_answer)\n",
        "workflow.add_node(\"generate_funny_response\", generate_funny_response)\n",
        "workflow.add_node(\"regenerate_query\", regenerate_query)\n",
        "workflow.add_node(\"end_max_iter\", end_max_iter)\n",
        "\n",
        "# Conditional logic\n",
        "workflow.add_conditional_edges(\n",
        "    \"check_relevance\",\n",
        "    router,\n",
        "    {\n",
        "        \"convert_to_sql\": \"convert_to_sql\",\n",
        "        \"generate_funny_response\": \"generate_funny_response\",\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"convert_to_sql\", \"execute_sql\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"execute_sql\",\n",
        "    execute_sql,\n",
        "    {\n",
        "        \"generate_answer\": \"generate_answer\",\n",
        "        \"regenerate_query\": \"regenerate_query\",\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"regenerate_query\",\n",
        "    check_attempts,\n",
        "    {\n",
        "        \"convert_to_sql\": \"convert_to_sql\",\n",
        "        \"end_max_iter\": \"end_max_iter\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Terminal paths\n",
        "workflow.add_edge(\"generate_answer\", END)\n",
        "workflow.add_edge(\"generate_funny_response\", END)\n",
        "workflow.add_edge(\"end_max_iter\", END)\n",
        "\n",
        "# Start point\n",
        "workflow.set_entry_point(\"check_relevance\")\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdf41476",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "fdf41476",
        "outputId": "a3eda4bc-9856-44ce-a997-afa344be6af9"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import display, Markdown\n",
        "\n",
        "# # Get the Mermaid diagram code directly\n",
        "# mermaid_code = app.get_graph().draw_mermaid()\n",
        "\n",
        "# # Display using Markdown\n",
        "# mermaid_markdown = f\"\"\"\n",
        "# ```mermaid\n",
        "# {mermaid_code}\n",
        "# ```\n",
        "# \"\"\"\n",
        "\n",
        "# display(Markdown(mermaid_markdown))\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "  display(Image(app.get_graph(xray=True).draw_mermaid_png(max_retries=5, retry_delay=2.0)))\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05291750",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05291750",
        "outputId": "47d5f7ba-49bd-4c60-872b-4072a17d0486"
      },
      "outputs": [],
      "source": [
        "# Initialize state\n",
        "state = {\n",
        "    \"question\": \"\",\n",
        "    \"chat_history\": [], # adding memory\n",
        "    \"sql_query\": \"\",\n",
        "    \"query_result\": \"\",\n",
        "    \"query_rows\": [],\n",
        "    \"attempts\": 0,\n",
        "    \"relevance\": \"\",\n",
        "    \"final_answer\": \"\",\n",
        "    \"sql_error\": False,\n",
        "}\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"User: \").strip()\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"Conversation ended.\")\n",
        "        break\n",
        "\n",
        "    state[\"question\"] = user_input\n",
        "    state[\"attempts\"] = 0  # reset attempts each new question\n",
        "\n",
        "    result = app.invoke(state)\n",
        "\n",
        "    answer = result.get(\"final_answer\", \"No response available.\")\n",
        "\n",
        "    print(f\"Assistant: {answer}\\n\")\n",
        "\n",
        "    state[\"chat_history\"].append({\"user\": user_input, \"assistant\": answer})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B8aNDH06CHuN",
      "metadata": {
        "id": "B8aNDH06CHuN"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ed5TWQMPkgtS",
      "metadata": {
        "id": "Ed5TWQMPkgtS"
      },
      "outputs": [],
      "source": [
        "gold_data_1 = [\n",
        "    {\n",
        "        \"question\": \"What are the names of all product categories?\",\n",
        "        \"query\": 'SELECT \"name\" FROM ADVENTUREWORKS.ADVENTUREWORKS.PRODUCTCATEGORY;'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"List all subcategories under each product category.\",\n",
        "        \"query\": 'SELECT pc.\"name\" AS category_name, psc.\"name\" AS subcategory_name FROM ADVENTUREWORKS.ADVENTUREWORKS.PRODUCTCATEGORY pc JOIN ADVENTUREWORKS.ADVENTUREWORKS.PRODUCTSUBCATEGORY psc ON pc.\"productcategoryid\" = psc.\"productcategoryid\";'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Show the average list price of products by color.\",\n",
        "        \"query\": 'SELECT \"color\", AVG(\"listprice\") AS avg_price FROM ADVENTUREWORKS.ADVENTUREWORKS.PRODUCT GROUP BY \"color\";'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How many product reviews are there for each product?\",\n",
        "        \"query\": 'SELECT \"productid\", COUNT(*) AS review_count FROM ADVENTUREWORKS.ADVENTUREWORKS.PRODUCTREVIEW GROUP BY \"productid\";'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Find the names of all currencies used in different country regions.\",\n",
        "        \"query\": 'SELECT DISTINCT \"currencycode\" FROM ADVENTUREWORKS.ADVENTUREWORKS.COUNTRYREGIONCURRENCY;'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the total sales for each salesperson?\",\n",
        "        \"query\": 'SELECT \"businessentityid\", \"salesytd\" FROM ADVENTUREWORKS.ADVENTUREWORKS.SALESPERSON;'\n",
        "    },\n",
        "]\n",
        "\n",
        "gold_data_2 =  [\n",
        "    {\n",
        "        \"question\": \"List sales orders with a total due greater than $10000.\",\n",
        "        \"query\": 'SELECT \"salesorderid\", \"totaldue\" FROM ADVENTUREWORKS.ADVENTUREWORKS.SALESORDERHEADER WHERE \"totaldue\" > 10000;'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the top 5 most expensive products?\",\n",
        "        \"query\": 'SELECT \"NAME\", \"listprice\" FROM ADVENTUREWORKS.ADVENTUREWORKS.PRODUCT ORDER BY \"listprice\" DESC LIMIT 5;'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Find all products with a safety stock level below 500.\",\n",
        "        \"query\": 'SELECT \"NAME\" FROM ADVENTUREWORKS.ADVENTUREWORKS.PRODUCT WHERE \"safetystocklevel\" < 500;'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Which salesperson has the highest sales year-to-date?\",\n",
        "        \"query\": 'SELECT \"businessentityid\", \"salesytd\" FROM ADVENTUREWORKS.ADVENTUREWORKS.SALESPERSON ORDER BY \"salesytd\" DESC LIMIT 1;'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"List all reviews with a rating of 5.\",\n",
        "        \"query\": 'SELECT \"reviewername\", \"comments\" FROM ADVENTUREWORKS.ADVENTUREWORKS.PRODUCTREVIEW WHERE \"rating\" = 5;'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Get all sales orders with their order date and total due.\",\n",
        "        \"query\": 'SELECT \"salesorderid\", \"orderdate\", \"totaldue\" FROM ADVENTUREWORKS.ADVENTUREWORKS.SALESORDERHEADER;'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Get the names of all products manufactured in 1 day.\",\n",
        "        \"query\": 'SELECT \"NAME\" FROM ADVENTUREWORKS.ADVENTUREWORKS.PRODUCT WHERE \"daystomanufacture\" = 1;'\n",
        "    },\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PtN9jdtu8w57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtN9jdtu8w57",
        "outputId": "4c4b16ad-92ed-4dec-d753-a6ba7721ab71"
      },
      "outputs": [],
      "source": [
        "print(gold_data_1[0]['question']), print(gold_data_1[0]['query'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5TOZLoPQ-Uyz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TOZLoPQ-Uyz",
        "outputId": "88397532-531e-4291-a539-3631437bbecf"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "  print(gold_data_2[i]['question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yt9hPbsJxfw7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt9hPbsJxfw7",
        "outputId": "00c6e6e6-8953-4610-8117-50932ff262da"
      },
      "outputs": [],
      "source": [
        "len(gold_data_1), len(gold_data_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C4UKfJxu-ElV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4UKfJxu-ElV",
        "outputId": "fa533973-5263-4da6-f5f8-caa23ffeac7e"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "\n",
        "for i in range(len(gold_data_2)):\n",
        "  state = {\n",
        "      \"question\": gold_data_2[i][\"question\"],\n",
        "      \"attempts\": 0,\n",
        "  }\n",
        "\n",
        "  result_state = app.invoke(state)\n",
        "  predicted_sql = result_state.get(\"sql_query\", \"Answer not found\")\n",
        "  print(result_state.get('final_answer', 'No answer'), '\\n----\\n')\n",
        "\n",
        "  predictions.append({\n",
        "      \"question\": gold_data_2[i][\"question\"],\n",
        "      \"gold_sql\": gold_data_2[i][\"query\"],\n",
        "      \"predicted_sql\": predicted_sql\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_TsV4YYQzdAq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TsV4YYQzdAq",
        "outputId": "1a0a18cf-2b2d-4d69-c8c0-348f52c5c610"
      },
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l0ltluE3hvz_",
      "metadata": {
        "id": "l0ltluE3hvz_"
      },
      "outputs": [],
      "source": [
        "def run_query(conn, query):\n",
        "  try:\n",
        "    with conn.cursor() as cur:\n",
        "      cur.execute(query)\n",
        "      return cur.fetchall()\n",
        "  except Exception as e:\n",
        "    print(f\"Query failed: {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bd9qhTz-p4F6",
      "metadata": {
        "id": "Bd9qhTz-p4F6"
      },
      "outputs": [],
      "source": [
        "# run_query(conn, 'SELECT \"color\" AS color, AVG(\"listprice\") AS average_list_price FROM PRODUCT GROUP BY \"color\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e9ade5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91e9ade5",
        "outputId": "cdaf52c3-c39f-4882-f098-a59dca71b11d"
      },
      "outputs": [],
      "source": [
        "exact_match_count = 0\n",
        "execution_match_count = 0\n",
        "\n",
        "for pred in predictions:\n",
        "  # Exact Match\n",
        "  if pred[\"gold_sql\"].strip().lower() == pred[\"predicted_sql\"].strip().lower():\n",
        "    exact_match_count += 1\n",
        "\n",
        "  # Execution Match\n",
        "  gold_result = run_query(conn, pred[\"gold_sql\"])\n",
        "  pred_result = run_query(conn, pred[\"predicted_sql\"])\n",
        "  if gold_result == pred_result:\n",
        "    execution_match_count += 1\n",
        "\n",
        "total = len(predictions)\n",
        "print(f\"Exact Match Accuracy: {exact_match_count}/{total} = {exact_match_count/total:.2f}\")\n",
        "print(f\"Execution Accuracy: {execution_match_count}/{total} = {execution_match_count/total:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XpOA2q32BmP_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpOA2q32BmP_",
        "outputId": "bb66af35-1dc9-4c55-9f3c-9f34d47a41cc"
      },
      "outputs": [],
      "source": [
        "# Results from first 6 examples gold_data_1\n",
        "# Exact Match Accuracy: 0/7 = 0\n",
        "# Execution Accuracy: 4/6 = 0.67\n",
        "\n",
        "total = len(gold_data_1) + len(gold_data_2)\n",
        "\n",
        "print(f'Exact Match: 1/{total} = {1/total:.4f}\\nExecution Match: 6/{total} = {6/total:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kKKVyZnMjZDB",
      "metadata": {
        "id": "kKKVyZnMjZDB"
      },
      "outputs": [],
      "source": [
        "import sqlglot\n",
        "from sqlglot.expressions import Select\n",
        "\n",
        "\n",
        "def extract_sql_components(sql: str) -> dict:\n",
        "    try:\n",
        "        parsed = sqlglot.parse_one(sql)\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"columns\": set(),\n",
        "            \"tables\": set(),\n",
        "            \"keywords\": set(),\n",
        "            \"error\": str(e),\n",
        "        }\n",
        "\n",
        "    columns: set[str] = set()\n",
        "    tables: set[str] = set()\n",
        "    keywords: set[str] = set()\n",
        "\n",
        "    for column in parsed.find_all(sqlglot.expressions.Column):\n",
        "        if column.name:\n",
        "            columns.add(column.name.lower())\n",
        "\n",
        "    for table in parsed.find_all(sqlglot.expressions.Table):\n",
        "        if table.name:\n",
        "            tables.add(table.name.lower())\n",
        "\n",
        "    if isinstance(parsed, Select):\n",
        "        if parsed.args.get(\"where\"):\n",
        "            keywords.add(\"where\")\n",
        "        if parsed.args.get(\"group\"):\n",
        "            keywords.add(\"group\")\n",
        "        if parsed.args.get(\"order\"):\n",
        "            keywords.add(\"order\")\n",
        "        if parsed.args.get(\"having\"):\n",
        "            keywords.add(\"having\")\n",
        "        if parsed.args.get(\"limit\"):\n",
        "            keywords.add(\"limit\")\n",
        "        if parsed.args.get(\"joins\"):\n",
        "            keywords.add(\"join\")\n",
        "\n",
        "    return {\n",
        "        \"columns\": columns,\n",
        "        \"tables\": tables,\n",
        "        \"keywords\": keywords,\n",
        "    }\n",
        "\n",
        "\n",
        "def jaccard_similarity(set1: set[str], set2: set[str]) -> float:\n",
        "    if not set1 and not set2:\n",
        "        return 1.0\n",
        "    return len(set1 & set2) / len(set1 | set2)\n",
        "\n",
        "\n",
        "def compute_sql_partial_match(predicted_sql: str, gold_sql: str) -> dict:\n",
        "    pred = extract_sql_components(predicted_sql)\n",
        "    gold = extract_sql_components(gold_sql)\n",
        "\n",
        "    col_score = jaccard_similarity(pred[\"columns\"], gold[\"columns\"])\n",
        "    table_score = jaccard_similarity(pred[\"tables\"], gold[\"tables\"])\n",
        "    keyword_score = jaccard_similarity(pred[\"keywords\"], gold[\"keywords\"])\n",
        "\n",
        "    total_score = 0.5 * col_score + 0.3 * table_score + 0.2 * keyword_score\n",
        "\n",
        "    return {\n",
        "        \"column_score\": col_score,\n",
        "        \"table_score\": table_score,\n",
        "        \"keyword_score\": keyword_score,\n",
        "        \"total_score\": total_score\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WAjqmKocjZAJ",
      "metadata": {
        "id": "WAjqmKocjZAJ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def normalize_sql(sql: str) -> list[str]:\n",
        "  sql = sql.lower().strip()\n",
        "  # Remove symbols for cleaner splitting\n",
        "  sql = re.sub(r'[(),;<>=]', '', sql)\n",
        "  return sql.split()\n",
        "\n",
        "\n",
        "def compute_f1(prediction: str|dict[str, float], truth: str|dict[str, float]) -> int | float:\n",
        "  if isinstance(prediction, str) and isinstance(truth, str):\n",
        "    pred_tokens = normalize_sql(prediction)\n",
        "    truth_tokens = normalize_sql(truth)\n",
        "\n",
        "  pred_tokens = prediction\n",
        "  truth_tokens = truth\n",
        "\n",
        "  # if either the prediction or the truth has no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "  if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "    return int(pred_tokens == truth_tokens)\n",
        "\n",
        "  common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "\n",
        "  # if there are no common tokens then f1 = 0\n",
        "  if len(common_tokens) == 0:\n",
        "    return 0\n",
        "\n",
        "  prec = len(common_tokens) / len(pred_tokens)\n",
        "  rec = len(common_tokens) / len(truth_tokens)\n",
        "\n",
        "  return 2 * (prec * rec) / (prec + rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P4KxOPCujY9B",
      "metadata": {
        "id": "P4KxOPCujY9B"
      },
      "outputs": [],
      "source": [
        "def f1_score(pred_sql, gold_sql):\n",
        "  pred = extract_sql_components(pred_sql)\n",
        "  gold = extract_sql_components(gold_sql)\n",
        "\n",
        "  column_f1 = compute_f1(pred[\"columns\"], gold[\"columns\"])\n",
        "  table_f1 = compute_f1(pred[\"tables\"], gold[\"tables\"])\n",
        "  keyword_f1 = compute_f1(pred[\"keywords\"], gold[\"keywords\"])\n",
        "\n",
        "  # weighted_f1 = 0.5 * column_f1 + 0.3 * table_f1 + 0.2 * keyword_f1 # weighted f1 score\n",
        "  macro_f1 = (column_f1 + table_f1 + keyword_f1) / 3 # macro f1 score\n",
        "  return {\n",
        "      \"column_f1\": column_f1,\n",
        "      \"table_f1\": table_f1,\n",
        "      \"keyword_f1\": keyword_f1,\n",
        "      \"macro_f1\": macro_f1,\n",
        "      # \"weighted_f1\": weighted_f1\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TcwKksaVjY2E",
      "metadata": {
        "id": "TcwKksaVjY2E"
      },
      "outputs": [],
      "source": [
        "f1_scores = []\n",
        "partial_matches = []\n",
        "\n",
        "for pred in predictions:\n",
        "  partial_matches.append(compute_sql_partial_match(pred[\"predicted_sql\"], pred[\"gold_sql\"]))\n",
        "  f1_scores.append(f1_score(pred[\"predicted_sql\"], pred[\"gold_sql\"]))\n",
        "\n",
        "avg_f1 = {\n",
        "  \"column_f1\": sum([f1[\"column_f1\"] for f1 in f1_scores]) / len(f1_scores),\n",
        "  \"table_f1\": sum([f1[\"table_f1\"] for f1 in f1_scores]) / len(f1_scores),\n",
        "  \"keyword_f1\": sum([f1[\"keyword_f1\"] for f1 in f1_scores]) / len(f1_scores),\n",
        "  \"macro_f1\": sum([f1[\"macro_f1\"] for f1 in f1_scores]) / len(f1_scores),\n",
        "  # \"weighted_f1\": sum([f1[\"weighted_f1\"] for f1 in f1_scores]) / len(f1_scores)\n",
        "}\n",
        "\n",
        "avg_partial_match = {\"total_score\": sum([pm[\"total_score\"] for pm in partial_matches]) / len(partial_matches)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ojGGGT2WkxRE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojGGGT2WkxRE",
        "outputId": "84a80ee9-0e18-4c6e-ff79-7b201f6f9e74"
      },
      "outputs": [],
      "source": [
        "print(f'f1-score: {avg_f1}\\nPartial Match: {avg_partial_match}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t8GVkz5XWGMs",
      "metadata": {
        "id": "t8GVkz5XWGMs"
      },
      "outputs": [],
      "source": [
        "# Results from first 6 examples gold_data_1\n",
        "# f1-score: {'column_f1': 0.7444444444444445, 'table_f1': 0.7777777777777777, 'keyword_f1': 0.9444444444444443, 'macro_f1': 0.8222222222222221}\n",
        "# Partial Match: {'total_score': 0.7555555555555555}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VTj_iYLZfoCk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTj_iYLZfoCk",
        "outputId": "3031ddc4-9a5d-4064-c025-f8e21d7d8e72"
      },
      "outputs": [],
      "source": [
        "n1 = len(gold_data_1)\n",
        "n2 = len(gold_data_2)\n",
        "total = n1 + n2\n",
        "\n",
        "# gold_data_1 f1-scores\n",
        "f1_part1 = {\n",
        "    'column_f1': 0.7444444444444445,\n",
        "    'table_f1': 0.7777777777777777,\n",
        "    'keyword_f1': 0.9444444444444443,\n",
        "    'macro_f1': 0.8222222222222221\n",
        "}\n",
        "\n",
        "# gold_data_2 f1-scores\n",
        "f1_part2 = {'column_f1': 0.9,\n",
        "            'table_f1': 1.0,\n",
        "            'keyword_f1': 1.0,\n",
        "            'macro_f1': 0.9666666666666667}\n",
        "\n",
        "# partial match\n",
        "partial_match_1 = 0.7555555555555555\n",
        "partial_match_2 = 0.9285714285714286\n",
        "\n",
        "# combined f1-scores using weighted average\n",
        "combined_f1 = {\n",
        "    key: (f1_part1[key] * n1 + f1_part2[key] * n2) / total\n",
        "    for key in f1_part1\n",
        "}\n",
        "\n",
        "# combined partial match scores\n",
        "combined_partial_match = (partial_match_1 * n1 + partial_match_2 * n2) / total\n",
        "\n",
        "\n",
        "print(\"Combined F1 Scores:\")\n",
        "for k, v in combined_f1.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "print(\"\\nCombined Partial Match Score:\")\n",
        "print(f\"total_score: {combined_partial_match:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d-1ieXKJXymq",
      "metadata": {
        "id": "d-1ieXKJXymq"
      },
      "outputs": [],
      "source": [
        "# AdventureWorks Schema\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.COUNTRYREGIONCURRENCY (\n",
        "# \t\"countryregioncode\" VARCHAR(16777216),\n",
        "# \t\"currencycode\" VARCHAR(16777216),\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.CURRENCYRATE (\n",
        "# \t\"currencyrateid\" NUMBER(38,0),\n",
        "# \t\"currencyratedate\" VARCHAR(16777216),\n",
        "# \t\"fromcurrencycode\" VARCHAR(16777216),\n",
        "# \t\"tocurrencycode\" VARCHAR(16777216),\n",
        "# \t\"averagerate\" FLOAT,\n",
        "# \t\"endofdayrate\" FLOAT,\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.PRODUCT (\n",
        "# \t\"productid\" NUMBER(38,0),\n",
        "# \tNAME VARCHAR(16777216),\n",
        "# \t\"productnumber\" VARCHAR(16777216),\n",
        "# \t\"makeflag\" VARCHAR(16777216),\n",
        "# \t\"finishedgoodsflag\" VARCHAR(16777216),\n",
        "# \t\"color\" VARCHAR(16777216),\n",
        "# \t\"safetystocklevel\" NUMBER(38,0),\n",
        "# \t\"reorderpoint\" NUMBER(38,0),\n",
        "# \t\"standardcost\" FLOAT,\n",
        "# \t\"listprice\" FLOAT,\n",
        "# \t\"size\" VARCHAR(16777216),\n",
        "# \t\"sizeunitmeasurecode\" VARCHAR(16777216),\n",
        "# \t\"weightunitmeasurecode\" VARCHAR(16777216),\n",
        "# \t\"weight\" VARCHAR(16777216),\n",
        "# \t\"daystomanufacture\" NUMBER(38,0),\n",
        "# \t\"productline\" VARCHAR(16777216),\n",
        "# \t\"class\" VARCHAR(16777216),\n",
        "# \t\"style\" VARCHAR(16777216),\n",
        "# \t\"productsubcategoryid\" VARCHAR(16777216),\n",
        "# \t\"productmodelid\" VARCHAR(16777216),\n",
        "# \t\"sellstartdate\" VARCHAR(16777216),\n",
        "# \t\"sellenddate\" VARCHAR(16777216),\n",
        "# \t\"discontinueddate\" VARCHAR(16777216),\n",
        "# \t\"rowguid\" VARCHAR(16777216),\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.PRODUCTCATEGORY (\n",
        "# \t\"productcategoryid\" NUMBER(38,0),\n",
        "# \t\"name\" VARCHAR(16777216),\n",
        "# \t\"rowguid\" VARCHAR(16777216),\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.PRODUCTDESCRIPTION (\n",
        "# \t\"productdescriptionid\" NUMBER(38,0),\n",
        "# \t\"description\" VARCHAR(16777216),\n",
        "# \t\"rowguid\" VARCHAR(16777216),\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.PRODUCTMODELPRODUCTDESCRIPTIONCULTURE (\n",
        "# \t\"productmodelid\" NUMBER(38,0),\n",
        "# \t\"productdescriptionid\" NUMBER(38,0),\n",
        "# \t\"cultureid\" VARCHAR(16777216),\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.PRODUCTREVIEW (\n",
        "# \t\"productreviewid\" NUMBER(38,0),\n",
        "# \t\"productid\" NUMBER(38,0),\n",
        "# \t\"reviewername\" VARCHAR(16777216),\n",
        "# \t\"reviewdate\" VARCHAR(16777216),\n",
        "# \t\"emailaddress\" VARCHAR(16777216),\n",
        "# \t\"rating\" NUMBER(38,0),\n",
        "# \t\"comments\" VARCHAR(16777216),\n",
        "# \t\"modifeddate\" VARCHAR(16777216),\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.PRODUCTSUBCATEGORY (\n",
        "# \t\"productsubcategoryid\" NUMBER(38,0),\n",
        "# \t\"productcategoryid\" NUMBER(38,0),\n",
        "# \t\"name\" VARCHAR(16777216),\n",
        "# \t\"rowguid\" VARCHAR(16777216),\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.SALESORDERDETAIL (\n",
        "# \t\"salesorderid\" NUMBER(38,0),\n",
        "# \t\"salesorderdetailid\" NUMBER(38,0),\n",
        "# \t\"carriertrackingnumber\" VARCHAR(16777216),\n",
        "# \t\"orderqty\" NUMBER(38,0),\n",
        "# \t\"productid\" NUMBER(38,0),\n",
        "# \t\"specialofferid\" NUMBER(38,0),\n",
        "# \t\"unitprice\" FLOAT,\n",
        "# \t\"unitpricediscount\" FLOAT,\n",
        "# \t\"rowguid\" VARCHAR(16777216),\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.SALESORDERHEADER (\n",
        "# \t\"salesorderid\" NUMBER(38,0),\n",
        "# \t\"revisionnumber\" NUMBER(38,0),\n",
        "# \t\"orderdate\" VARCHAR(16777216),\n",
        "# \t\"duedate\" VARCHAR(16777216),\n",
        "# \t\"shipdate\" VARCHAR(16777216),\n",
        "# \tSTATUS VARCHAR(16777216),\n",
        "# \t\"onlineorderflag\" VARCHAR(16777216),\n",
        "# \t\"purchaseordernumber\" VARCHAR(16777216),\n",
        "# \t\"accountnumber\" VARCHAR(16777216),\n",
        "# \t\"customerid\" NUMBER(38,0),\n",
        "# \t\"salespersonid\" VARCHAR(16777216),\n",
        "# \t\"territoryid\" NUMBER(38,0),\n",
        "# \t\"billtoaddressid\" NUMBER(38,0),\n",
        "# \t\"shiptoaddressid\" NUMBER(38,0),\n",
        "# \t\"shipmethodid\" NUMBER(38,0),\n",
        "# \t\"creditcardid\" VARCHAR(16777216),\n",
        "# \t\"creditcardapprovalcode\" VARCHAR(16777216),\n",
        "# \t\"currencyrateid\" VARCHAR(16777216),\n",
        "# \t\"subtotal\" FLOAT,\n",
        "# \t\"taxamt\" FLOAT,\n",
        "# \t\"freight\" FLOAT,\n",
        "# \t\"totaldue\" FLOAT,\n",
        "# \t\"comment\" VARCHAR(16777216),\n",
        "# \t\"rowguid\" VARCHAR(16777216),\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.SALESPERSON (\n",
        "# \t\"businessentityid\" NUMBER(38,0),\n",
        "# \t\"territoryid\" VARCHAR(16777216),\n",
        "# \t\"salesquota\" VARCHAR(16777216),\n",
        "# \t\"bonus\" NUMBER(38,0),\n",
        "# \t\"commissionpct\" FLOAT,\n",
        "# \t\"salesytd\" FLOAT,\n",
        "# \t\"saleslastyear\" FLOAT,\n",
        "# \t\"rowguid\" VARCHAR(16777216),\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.SALESPERSONQUOTAHISTORY (\n",
        "# \t\"BusinessEntityID\" NUMBER(38,0),\n",
        "# \t\"QuotaDate\" VARCHAR(16777216),\n",
        "# \t\"SalesQuota\" FLOAT,\n",
        "# \t\"rowguid\" VARCHAR(16777216),\n",
        "# \t\"ModifiedDate\" VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "# create or replace TABLE ADVENTUREWORKS.ADVENTUREWORKS.SALESTERRITORY (\n",
        "# \t\"territoryid\" NUMBER(38,0),\n",
        "# \t\"name\" VARCHAR(16777216),\n",
        "# \t\"countryregioncode\" VARCHAR(16777216),\n",
        "# \t\"group\" VARCHAR(16777216),\n",
        "# \t\"salesytd\" FLOAT,\n",
        "# \t\"saleslastyear\" FLOAT,\n",
        "# \t\"costytd\" FLOAT,\n",
        "# \t\"costlastyear\" FLOAT,\n",
        "# \t\"rowguid\" VARCHAR(16777216),\n",
        "# \t\"modifieddate\" VARCHAR(16777216)\n",
        "# );"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
